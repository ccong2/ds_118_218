[
  {
    "objectID": "modules/index3.html",
    "href": "modules/index3.html",
    "title": "Module 3 Communicate Data Science",
    "section": "",
    "text": "Transform static analyses into interactive tools that invite users to explore and discover insights on their own.\n\nInteractive Map and Dashboard\nWeb-app storytelling"
  },
  {
    "objectID": "modules/index1.html",
    "href": "modules/index1.html",
    "title": "Module 1 Descriptive Data Science",
    "section": "",
    "text": "We‚Äôll explore the foundations of descriptive data science, learning how to summarize, visualize, and interpret datasets to uncover meaningful patterns.\n\nIntro to R\nUrban Science History and Data Prep\nData Manipulation and Visualization I\nData Manipulation and Visualization II"
  },
  {
    "objectID": "labs/index.html",
    "href": "labs/index.html",
    "title": "Lab Overview",
    "section": "",
    "text": "Here you‚Äôll find links and resources for each lab session:\n\nLab 1: Data Wrangling: Cambridge Building Energy\nLab 2: Making Exploratory Graphs: Opportunity Zones\nLab 3: Enhancing Visualizations: Airbnb Data\nLab 4: Spatial Analysis: Neighborhood Built Environment\nLab 5: Census Data: Describe Population Change\nLab 6: Online Map and Dashboard\nLab 7: Shiny Apps\nLab 8: Build Machine Learning Models: Predict Housing Prices\nLab 9: Tree-Based Models and Parameter Tuning\nLab 10: Fairness-Aware ML Models: Predict Recidivism"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the 11.118/218",
    "section": "",
    "text": "Urban science draws on statistics, visualization, and spatial analysis techniques to gain deeper insights into cities and actively contribute to their development. In this course, we‚Äôll dive into the dynamic world of urban science by learning how to tell stories about cities and neighborhoods, covering a range of topics including demographic analysis, health and transportation, and using R as our primary quantitative analysis and interactive visualization tool.\n\n\n  \n    \n      Module 1Descriptive Data Science\n    \n  \n\n  \n    \n      Module 2Geospatial Data Science\n    \n  \n\n  \n    \n      Module 3Storytelling Data Science\n    \n  \n\n  \n    \n      Module 4Predictive Data Science"
  },
  {
    "objectID": "labs/lab1.html",
    "href": "labs/lab1.html",
    "title": "Get started with ",
    "section": "",
    "text": "In this exercise, we will first practice working with Quarto Document. Then we‚Äôll dive into a dataset to see how we can start pulling out useful information."
  },
  {
    "objectID": "labs/lab1.html#set-up-a-new-project",
    "href": "labs/lab1.html#set-up-a-new-project",
    "title": "Get started with ",
    "section": "Set up a New Project",
    "text": "Set up a New Project\nWe have talked about looking for files paths in class,\n\nImport dataset using direct path: ‚ùå Not recommended. Hard-coded paths break easily.\nManually set up a working directory setwd(): üòï This works fine until when you want to move your working folder or share your work. You‚Äôll constantly need to re-set the directory.\nSet up a Project: üéâ Recommended. R projects organize all files related to a project in one place and setting up relative file paths. Let‚Äôs start by setting up a project for our exercise.\n\nLaunch RStudio, then click File - New Project‚Ä¶ A dialog box will open up. Select New Directory, then New Project. Here, you can create a new folder to save everything related to this project. For example, I chose my D:/Fall25 folder and created a new folder there called Lab 1:\n\nClick the button ‚ÄúCreate Project‚Äù. R will take a second to refresh.\nThen you will see in your Files tab that you have been directed to your current working directory: D:/Fall25/Lab 1. You will also see a .Rproj file in that folder.\n\nThe .Rproj file serves as a reference point that R uses to locate all files associated with the project. If you save all files related to Lab 1 in this folder, all relative paths remain intact and consistently applied.\nNote: In future sessions, I may provide you with a project folder containing data. As long as you launch RStudio by double-clicking the .Rproj file, you will be taken directly to the project‚Äôs home directory."
  },
  {
    "objectID": "labs/lab1.html#practice-formatting-text-with-quarto",
    "href": "labs/lab1.html#practice-formatting-text-with-quarto",
    "title": "Get started with ",
    "section": "Practice formatting text with Quarto",
    "text": "Practice formatting text with Quarto\nNow go to File - New File - Quarto Document to create a new Quarto document. The prompt shown below will appear. Type in a document title (e.g.¬†Lab 1) and your name. Keep the radio button for HTML selected.\n\nYou will then see a template file. At the very top you will see the YAML (or ‚ÄúYet Another Markdown Language‚Äù) header which begins and ends with three dashes ---. The YAML header determines how your document will be rendered to your desired output format. Now it specifies the title, author, output format and text editor.\nTo get an idea of how everything works, let‚Äôs click the ‚ÄúRender‚Äù button on top of your toolbar.\nWhen prompted, give this file a name, it should be saved in the folder where your ‚Äú.Rproj‚Äù file is, as a .qmd file.\nYou will now see a formatted document in a web browser. Switch between your code and the document back and forth to see where each part of the code is placed in the rendered HTML file.\nThere can be other options specified in the YAML, particularly if you are rendering to a format other than HTML (such as pdf, or Word, see all formats).\nOn the very left of this toolbar, click the ‚ÄúSource‚Äù button to switch Markdown editing mode. These sections of text typically explain or provide context for the code and graphics, and they are formatted using Markdown syntax. For example:\n\n#: a header element.\n**: bold text.\n*: italic text.\n` : code blocks.\n\nOverall, the Visual interface looks pretty much like a Word document. There is a toolbar that allows you to edit text formats, create a bullet list, insert a link or an image, insert a code block, etc.\nNow let‚Äôs delete everything below the YAML header in this test file, so that we will start creating our own formatted report.\n\nExercise\nIn 2014, the City of Cambridge passed a local ordinance on building energy use disclosure. Spend a few moments reviewing this website to become familiar with the ordinance (in general).\nThen, add 2-3 sentences below your YAML section that explain the following:\n\nWhat does the Building Energy Use Disclosure Ordinance require?\nWhat kind of data have been compiled and where to find them?\n\nYou may edit your text either in the ‚ÄúSource‚Äù or ‚ÄúVisual‚Äù panel, or toggle between them to get familiar with both. Make sure to make gratuitous use of bold, italics, bullet points, etc. in your text.\nWhen you finish, save your file and click Render again. You can immediately see your nicely formatted document in a web browser."
  },
  {
    "objectID": "labs/lab1.html#select-selects-a-subset-of-columns.",
    "href": "labs/lab1.html#select-selects-a-subset-of-columns.",
    "title": "Get started with ",
    "section": "Select: selects a subset of columns.",
    "text": "Select: selects a subset of columns.\nIn the energy dataset, we probably don‚Äôt need all of the 67 columns. So we can make it a smaller dataset by specifying a few columns to keep.\ndataset |&gt; select(Column1, Column2)\nInsert a new code chunk in your document to select a few variables. You don‚Äôt need the copy and paste the code below, let‚Äôs type the variable names ourselves to see what shows up along the way. You can type the pipe |&gt; operator using Shift+Ctrl/Cmd+M.\nenergy |&gt;\n  select(\n    `Data Year`,\n    `BEUDO Category`,\n    Owner,\n    `Year Built`,\n    `Primary Property Type - Self Selected`,\n    `Total GHG Emissions (Metric Tons CO2e)`,\n    `Total GHG Emissions Intensity (kgCO2e/ft2)`,\n    Latitude,\n    Longitude\n  ) \nSome of the column names are surrounded by backticks (`), that‚Äôs because they include special characters or spaces (such as spaces and () ). The use of backticks is to preserve these unique names. If you just keep typing the column names, dplyr will populate the correct names for you.\nHowever, it would be helpful to make the columns names clean and easy to read. What we usually do is to rename the columns using snake-case naming conventions while we are making selections.\n\nenergy &lt;- energy |&gt;\n  select(\n    data_year = `Data Year`,\n    BEUDO_category = `BEUDO Category`,\n    owner = Owner,\n    year_built = `Year Built`,\n    property_type = `Primary Property Type - Self Selected`,\n    ghg_emission = `Total GHG Emissions (Metric Tons CO2e)`,\n    ghg_intensity = `Total GHG Emissions Intensity (kgCO2e/ft2)`,\n    latitude = Latitude,\n    longitude = Longitude\n  ) \n\nClick the energy variable in your Environment panel now to browse this smaller dataset that only include 9 variables, with clean column names.\nNote: &lt;- and |&gt; look quite similar but it‚Äôs important to distinguish them. |&gt; works data through functions but doesn‚Äôt store the result unless assigned. &lt;- assigns (stores) the result to a variable."
  },
  {
    "objectID": "labs/lab1.html#filter-select-a-subset-of-rows",
    "href": "labs/lab1.html#filter-select-a-subset-of-rows",
    "title": "Get started with ",
    "section": "filter: Select a subset of rows",
    "text": "filter: Select a subset of rows\nNow let‚Äôs create a new dataset that only contains energy use records from MIT buildings.\ndataset |&gt; filter(&lt;condition&gt;)\nTake a look at how we achieve this using the following code:\n{r}\nenergy |&gt; \n  filter(owner == \"MASSACHUSETTS INSTITUTE OF TECHNOLOGY\")\nResults will be showing in your console. You‚Äôll notice that some entries are missing records for total GHG emissions, which appear as NA under the ‚Äúghg_emission‚Äù and ‚Äúghg_intensity‚Äù column. If we want to simplify the dataset by keeping only the rows with valid GHG emission records, we can apply that as an additional filter condition too.\nProceed to insert a new code chunk in your document like the one below. Now we are filtering with two conditions: MIT buildings, and have emission data. We are assigning the result to a new variable ‚Äúmit_energy‚Äù.\n\nmit_energy &lt;- energy |&gt; \n  filter(owner == \"MASSACHUSETTS INSTITUTE OF TECHNOLOGY\") |&gt; \n  filter(!is.na(ghg_emission))\n\nis.na() is a function commonly used to check whether each value in a column is missing (NA). The ! is a logical negation operator, so !is.na() checks for values that are not missing. It returns TRUE for non-missing values and FALSE for missing values."
  },
  {
    "objectID": "labs/lab1.html#summarise-create-a-summary-of-your-data",
    "href": "labs/lab1.html#summarise-create-a-summary-of-your-data",
    "title": "Get started with ",
    "section": "Summarise: Create a summary of your data",
    "text": "Summarise: Create a summary of your data\nGo ahead and run the following code and observe how we got the result:\n\nmit_energy |&gt; \n  summarise(avg_emission = mean(ghg_emission))\n\n# A tibble: 1 √ó 1\n  avg_emission\n         &lt;dbl&gt;\n1        1510.\n\n\nIt calculates the average of the column ‚Äúghg_emission‚Äù of the entire dataset, and names the result ‚Äúavg_emission‚Äù. The result says, of all MIT buildings, through all years, the average annual GHG emission is ~1510 MTCO2e.\nsummarise calculates summary statistics, like a total, mean, or count, across all values in the dataset. However, when used along with group_by(), it calculates each group separately, collapsing each group into its own summary row.\nFor instance, below we calculate the average GHG emissions by data_year, which is the year when the energy record was taken.\n\nmit_energy |&gt; \n  group_by(year = data_year) |&gt; \n  summarise(avg_emission = mean(ghg_emission))\n\n# A tibble: 9 √ó 2\n   year avg_emission\n  &lt;dbl&gt;        &lt;dbl&gt;\n1  2015        1625.\n2  2016        1480.\n3  2017        1572.\n4  2018        1493.\n5  2019        1541.\n6  2020        1448.\n7  2021        1483.\n8  2022        1484.\n9  2023        1462.\n\n\nThis says, in 2015, the average annual GHG emission was ~1625 MTCO2e., and in 2016, it was ~1480 MTCO2e., so on and so forth."
  },
  {
    "objectID": "labs/lab1.html#exercise-3",
    "href": "labs/lab1.html#exercise-3",
    "title": "Get started with ",
    "section": "Exercise",
    "text": "Exercise\nInsert a few new code chunks below this one to document your code and show your results.¬†\n\nFrom the mit_energy dataset, create a subset of all non-residential buildings, that were built before the year 2000. (Hint: which function would you use?). How many such buildings are there?\nFrom the mit_energy dataset, compare the GHG emissions by property type (Hint: which column has this information?), and generate a table that shows the following results:\n\n\nYou can create this table mostly by modifying our example code, however, there are a few small things you can experiment on:\n\nThe calculated average numbers in this table are rounded to 2 decimals, how to achieve that?\nThe table is arranged in descending order based on the ‚Äúavg_emission‚Äù column, how to do that? (Hint)\n\nWe are already asking questions and finding insights from the dataset! If the results in this table look interesting/surprising/expected to you, write a few sentences describing what you see from the analysis.\n\nLastly, and just for fun, copy and paste the following code to your document. (If your R says it can‚Äôt find mapview, run the line install.packages(\"mapview\"))\n\n#install.packages(\"mapview\")\nlibrary(mapview)\nmapview(\n  mit_energy |&gt; na.omit(),\n  xcol = \"longitude\", ycol = \"latitude\",\n  crs = 4326,\n  grid = FALSE\n)\n\n\n\n\n\n\nThe dataset we have includes ‚ÄúLongitude‚Äù and ‚ÄúLatitude‚Äù columns, which I love, because it indicates that location information is readily available and can be visualized in a map!\nNow Save, Render your document again. You have now created a nice, multi-media report using Quarto!\n------\nIn this lab we have introduced how to create and develop a Quarto Document. We have also worked with a few commonly-used dplyr functions including select, filter, group_by and summarise. This is the beginning of our data wrangling and leads to the work next week."
  },
  {
    "objectID": "labs/lab2.html",
    "href": "labs/lab2.html",
    "title": "Exploratory Data Analysis with ",
    "section": "",
    "text": "This week‚Äôs Lab Exercise focuses on the dplyr package and the ggplot2 package. It also engages with data visualization best practices by demonstrating how to create and interpret a variety of graphics.\nExploratory data analysis (EDA) is a phase of a data science workflow that emphasizes getting to know the data before rushing to analyze it. EDA usually involves checking the quality of the data, then creating diagnostic plots to spot patterns, issues, or unusual values, so that we can better decide on the more detailed analyses to do next."
  },
  {
    "objectID": "labs/lab2.html#download-data-and-load-packages",
    "href": "labs/lab2.html#download-data-and-load-packages",
    "title": "Exploratory Data Analysis with ",
    "section": "Download data and load packages",
    "text": "Download data and load packages\nI recommend creating a separate folder for each assignment. For today, make a folder called ‚ÄúLab 2‚Äù to contain your data and script. To do that, open RStudio and navigate to File &gt; New Project‚Ä¶ When the dialog box will appear, choose Existing Directory. Proceed to create a new R project within your ‚ÄúLab 2‚Äù folder.\nAs you read through the tutorial, you can use an R script to type and run the code. You will be asked to start a Quarto Document when you begin your exercises at the end of this tutorial.\nNow navigate to Urban Institute‚Äôs website about Opportunity Zones, find the link ‚ÄúDownload tract-level data on all Opportunity Zones‚Äù, and download this dataset to a ‚Äúdata‚Äù folder in your Lab 2 project folder. Rename the file if you need.\nTo stay organized, we should load packages at the beginning of our script. These are the three packages we are going to use today. You may want to run install.packages() on readxl and DataExplorer if it‚Äôs the first time you use them.\n\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(DataExplorer)"
  },
  {
    "objectID": "labs/lab2.html#data-cleaning",
    "href": "labs/lab2.html#data-cleaning",
    "title": "Exploratory Data Analysis with ",
    "section": "Data cleaning",
    "text": "Data cleaning\nThe mutate function in dplyr allows you to modify your dataset by either adding new columns, or updating values in existing columns. You can transform existing variables using a wide range of operations, such as arithmetic calculations, conditional expressions, or functions.\nFor example, the Urban Institute has coded the designated variable as either taking a value of 1 when designated, or NA when not. Since the NA and 1 here have no mathematical meaning, it would be easier to read if the column simply showed text like ‚ÄúDesignated‚Äù or ‚ÄúNot Designated.‚Äù In the following code, we are updating the column DesignatedOZ.\n\nozs &lt;- data |&gt;\n  mutate(DesignatedOZ =\n           ifelse(is.na(DesignatedOZ), \n                  \"not_designated\", \"designated\"))\n\nThe ifelse(condition, \"not_designated\", \"designated\") is used to set the value of DesignatedOZ based on the condition: If DesignatedOZ is NA, it assigns the text ‚Äúnot_designated‚Äù. Otherwise, it assigns ‚Äúdesignated‚Äù. After the modification, we can make a quick count of both types of tracts.\n\nozs |&gt; \n  count(DesignatedOZ) \n\n# A tibble: 2 √ó 2\n  DesignatedOZ       n\n  &lt;chr&gt;          &lt;int&gt;\n1 designated      8764\n2 not_designated 33414\n\n\nThere are a few columns (such as SE_Flag) that won‚Äôt be very helpful for this analysis. We can select a subset of columns to work on. If there is a minus sign in front of the column names, that means to drop these specified columns.\n\nozs &lt;- \n  ozs |&gt; \n  select(-c(dec_score, SE_Flag, pctown, Metro, Micro, NoCBSAType))\n\nA reminder of when to use &lt;- (assign to).\n\nUse &lt;-: when you want to save our result. In the example above, we are keeping the original data intact, but created a new object called ozs.\nDo not to use &lt;-: If you only want to view results without modifying the object.\n\nOne of the characteristics tracked in the Urban Institute data is the median household income for each tract (medhhincome). We can take a look at whether there‚Äôs a difference in the median household income for designated and not-designated census tracts.\nHowever, if you scroll down to the bottom of the dataset in the data viewer, you will notice there are quite a few of NAs in the Census demographic columns.\nHow many missing values are there, and how many would be a hurdle for my analysis? It will be great to have a sense of completeness in terms of what proportion of a field actually holds data. Below we use is.na to check if each element in ozs is NA, and use colSums to sum up all TRUE values by column.\n\ncolSums(is.na(ozs))\n\n           geoid            state     DesignatedOZ           county \n               0               23                0               98 \n            Type       Population      medhhincome      PovertyRate \n               0              112              249              141 \n       unemprate         medvalue          medrent severerentburden \n             141             1106              395              189 \n     vacancyrate         pctwhite         pctBlack      pctHispanic \n             167              131              131              131 \n    pctAAPIalone       pctunder18        pctover64        HSorlower \n             131              131              131              132 \n      BAorhigher \n             132 \n\n\nAnother way to observe missing values in each column is to use plot_missing in the DataExplorer package.\n\nDataExplorer::plot_missing(ozs)\n\n\n\n\n\n\n\n\nplot_missing calculates the proportion of missing values in a given variable, and makes some judgemental calls of whether the missing is significant, indicated by ‚ÄúGood‚Äù, ‚ÄúOK‚Äù, and ‚ÄúBad‚Äù. (Feel feel to check out ?plot_missing in your console. What are the default ranges for these three categories?) Overall, most of our columns have a very small portion of missing values (less than 1%) and would not create significant representative issues. However, when performing calculations, we need to include the na.rm = TRUE argument, indicating that we are calculating based on the available 99%."
  },
  {
    "objectID": "labs/lab2.html#create-summary-tables",
    "href": "labs/lab2.html#create-summary-tables",
    "title": "Exploratory Data Analysis with ",
    "section": "Create summary tables",
    "text": "Create summary tables\nWe can calculate the average median household income for designated and not-designated census tracts. That is to collapse the stat summary of median household income summarise(mean(medhhincome)) into two groups group_by(DesignatedOZ) .\n\nozs |&gt; \n  group_by(DesignatedOZ) |&gt; \n  summarise(\n    Tracts = n(),\n    Income = mean(medhhincome, na.rm=TRUE))\n\n# A tibble: 2 √ó 3\n  DesignatedOZ   Tracts Income\n  &lt;chr&gt;           &lt;int&gt;  &lt;dbl&gt;\n1 designated       8764 33346.\n2 not_designated  33414 44446.\n\n\nWe can also put two columns in the group_by function, for instance, grouping first by state and then by eligibility, allowing for comparisons within each state.\n\nozs |&gt; \n  group_by(state, DesignatedOZ) |&gt; \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE))\n\n# A tibble: 108 √ó 3\n# Groups:   state [57]\n   state          DesignatedOZ   Income\n   &lt;chr&gt;          &lt;chr&gt;           &lt;dbl&gt;\n 1 Alabama        designated     30044.\n 2 Alabama        not_designated 36542.\n 3 Alaska         designated     49840.\n 4 Alaska         not_designated 54784.\n 5 American Samoa designated       NaN \n 6 Arizona        designated     34373.\n 7 Arizona        not_designated 40961.\n 8 Arkansas       designated     31254.\n 9 Arkansas       not_designated 37814.\n10 California     designated     36134.\n# ‚Ñπ 98 more rows\n\n\n‚ÄúAmerican Samoa‚Äù might have caught our attention at this step, because we‚Äôve got NaN (not a number), indicating that ALL values in this region are NA. This prompts us to return to the dataset and further clean our data.\nAre there any other states where all economic variable values are NA, possibly meaning that we have no records for tracts in those areas?\n\nozs |&gt; \n  group_by(state) |&gt; \n  summarize(all_na = all(is.na(Population))) |&gt; \n  filter(all_na == TRUE)\n\n# A tibble: 5 √ó 2\n  state                    all_na\n  &lt;chr&gt;                    &lt;lgl&gt; \n1 American Samoa           TRUE  \n2 Guam                     TRUE  \n3 Northern Mariana Islands TRUE  \n4 Virgin Islands           TRUE  \n5 &lt;NA&gt;                     TRUE  \n\n\nThe all(is.na(Population)) function checks if all values in the Population column for that state are NA. If they are, all_na will be TRUE. If we aim to produce economic stats, and find these states uninformative, we can choose to remove them from our dataset:\n\nozs &lt;- \n  ozs |&gt; \n  filter(!state %in% c(\"American Samoa\", \"Guam\", \"Northern Mariana Islands\", \"Virgin Islands\") & !is.na(state))\n\nThen perform the summary again:\n\nozs |&gt; \n  group_by(state, DesignatedOZ) |&gt; \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE))\n\n# A tibble: 103 √ó 3\n# Groups:   state [52]\n   state      DesignatedOZ   Income\n   &lt;chr&gt;      &lt;chr&gt;           &lt;dbl&gt;\n 1 Alabama    designated     30044.\n 2 Alabama    not_designated 36542.\n 3 Alaska     designated     49840.\n 4 Alaska     not_designated 54784.\n 5 Arizona    designated     34373.\n 6 Arizona    not_designated 40961.\n 7 Arkansas   designated     31254.\n 8 Arkansas   not_designated 37814.\n 9 California designated     36134.\n10 California not_designated 50858.\n# ‚Ñπ 93 more rows\n\n\nIt would be even more helpful to reshape our summary table, arranging it in a way that each state has a single row with separate columns for designated and not-designated income value.\nFunctions pivot_wider() and pivot_longer() are useful for reshaping data. pivot_wider() adds columns to a dataset by transitioning content from rows to columns. pivot_longer() does the opposite: making a dataset longer by transitioning columns to rows.\nIn our case, let‚Äôs use pivot_wider() to transition our Designated and Not Designated rows into columns.\n\nozs |&gt; \n  group_by(state, DesignatedOZ) |&gt; \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE)) |&gt; \n  pivot_wider(names_from = DesignatedOZ, values_from = Income)\n\n# A tibble: 52 √ó 3\n# Groups:   state [52]\n   state                designated not_designated\n   &lt;chr&gt;                     &lt;dbl&gt;          &lt;dbl&gt;\n 1 Alabama                  30044.         36542.\n 2 Alaska                   49840.         54784.\n 3 Arizona                  34373.         40961.\n 4 Arkansas                 31254.         37814.\n 5 California               36134.         50858.\n 6 Colorado                 41138.         49601.\n 7 Connecticut              36760.         51389.\n 8 Delaware                 40971.         50143.\n 9 District of Columbia     38291.         62840.\n10 Florida                  31015.         40931.\n# ‚Ñπ 42 more rows\n\n\nAdd one more step, we can create a new column, to calculate and show the difference in income between designated and not designated tracts:\n\nozs |&gt; \n  group_by(state, DesignatedOZ) |&gt; \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE)) |&gt; \n  pivot_wider(names_from = DesignatedOZ, values_from = Income) |&gt; \n  mutate(Difference = designated - not_designated)\n\n# A tibble: 52 √ó 4\n# Groups:   state [52]\n   state                designated not_designated Difference\n   &lt;chr&gt;                     &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;\n 1 Alabama                  30044.         36542.     -6498.\n 2 Alaska                   49840.         54784.     -4944.\n 3 Arizona                  34373.         40961.     -6588.\n 4 Arkansas                 31254.         37814.     -6560.\n 5 California               36134.         50858.    -14724.\n 6 Colorado                 41138.         49601.     -8463.\n 7 Connecticut              36760.         51389.    -14628.\n 8 Delaware                 40971.         50143.     -9172.\n 9 District of Columbia     38291.         62840.    -24548.\n10 Florida                  31015.         40931.     -9916.\n# ‚Ñπ 42 more rows"
  },
  {
    "objectID": "labs/lab2.html#distribution-of-one-variable",
    "href": "labs/lab2.html#distribution-of-one-variable",
    "title": "Exploratory Data Analysis with ",
    "section": "Distribution of one variable",
    "text": "Distribution of one variable\n\nBoxplot\nThe code below creates a boxplot to contrast the distribution of poverty rates between designated opportunity zones and undesignated zones. We are using grammars of the ggplot function introduced in class, then adding more features with the + operator and other functions listed in the package reference.\n\nozs |&gt; ggplot(): This is the main plotting function. ozs is your dataset we use.\ngeom_boxplot(): Recall that geometric layers are called geoms_*. It tells R what kind of geometry you want to use visualize the data.\naes(x = DesignatedOZ, y = PovertyRate): The aes() function is where you tell ggplot which variable goes on the x axis followed by which variable goes on the y axis.\nThe third aesthetic element is fill, which indicates the filled color of the boxplot. Why we are not using color? fill controls the color of the inside of a shape, color controls the outline.\nWe used a new function scale_y_continuous to specify y axis properties. Here we are making sure the poverty rate are labeled as percentages. If you remove this line, they will by default show as decimal numbers.\n\n\nozs |&gt; \n  ggplot(aes(x = DesignatedOZ, y = PovertyRate, fill = DesignatedOZ)) +\n  geom_boxplot() + \n  scale_y_continuous(labels = scales::percent) +\n  labs(x = \"Opportunity Zone Eligible Tracts\", y = \"Poverty Rate\", fill = \"Tracts\")\n\n\n\n\n\n\n\n\nBy comparing the 50th percentile (or median, the horizontal line inside each box) we can see that tracts designated as Opportunity Zones have a higher median poverty rate compared with those not designated.\nThe heights of the boxes themselves give us an indication of how closely around the median all values in the dataset are concentrated: the degree of dispersion or spread.\nThe vertical lines are called whiskers and extend upward and downward to the farthest non-outlier values. More points beyond these lines indicates higher variation.\n\n\nDensity plot\nBy modifying the last code chunk, we can make a density plot (using geom_density) to describe the distribution of poverty rate.\nA density plot can be understood as a smoothed version of the histogram. It takes the count of data points at discrete poverty rate levels and smooths it out into a continuous curve.\n\nozs |&gt; \n  ggplot(aes(x = PovertyRate, fill = DesignatedOZ)) +\n  geom_density() + \n  scale_x_continuous(labels = scales::percent) +\n  labs(x = \"Poverty Rate\", fill = \"Tracts\")\n\n\n\n\n\n\n\n\nIf you look at both the boxplot and the density plot, they‚Äôre both telling us that the poverty rate values in the non-designated zones are more spread out, and the median is higher.\n\n\nCombinations of basic graphs to create composite views\nOne of the coolest thing about ggplot is that we can plot multiple geom_ on top of each other. For instance, we can combine the two plots above, to show both the curves and the essential statistics in the boxplot. The following code uses two geom_(Check out geom_violin for more!), and introduces several new arguments for fine-tuning the cosmetics.\n\ntrim = FALSE: If TRUE (default), trim the tails of the violins to the range of the data. If FALSE, don‚Äôt trim the tails and show the complete distribution.\nalpha = 0.5: the transparency of the plotting area.\ncoord_flip(): whether the y axis is displayed horizonally or vertically.\nlegend.position = \"none\": the position of legend (‚Äúleft‚Äù, ‚Äúright‚Äù, ‚Äúbottom‚Äù, ‚Äútop‚Äù, or two-element numeric vector), or not showing the legend (‚Äúnone‚Äù).\n\n\nozs |&gt; ggplot() +\n  geom_violin(aes(x = DesignatedOZ, y = PovertyRate, fill = DesignatedOZ), \n              trim = FALSE, alpha = 0.5) +\n  geom_boxplot(aes(x = DesignatedOZ, y = PovertyRate), \n               color = \"black\", width = .15, alpha = 0.8) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(\n    x = \"Opportunity Zone Eligible Tracts\",\n    y = \"Poverty Rate\",\n    title = \"Distribution of Poverty Rate\"\n  ) +\n  coord_flip() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nA useful way to learn ggplot is to take some arguments out, run it again, and see how it changes the plot. What you see is what you get: every tweak you make shows up right away in the graph."
  },
  {
    "objectID": "labs/lab2.html#relationship-between-two-variables",
    "href": "labs/lab2.html#relationship-between-two-variables",
    "title": "Exploratory Data Analysis with ",
    "section": "Relationship between two variables",
    "text": "Relationship between two variables\n\nScatter Plot\nWe are often interested in ‚Äúbivariate relationships‚Äù - how two variables relate to one another. Scatterplots are often used to visualize the association between two continuous variables. They can reveal much about the nature of the relationship between two variables.\nLet‚Äôs use create a subset of Massachusetts data to perform this part of analysis. (We could use the nationwide dataset, but there will be over 40,000 points showing on the graph, which will not be pleasing to the eye).\n\nozs_ma &lt;- \n  ozs |&gt; filter(state == \"Massachusetts\") \n\nWe begin by creating a scatterplot of poverty rate and racial distribution. Note that we used theme_bw, which is a theme template for a cleaner look.\n\nozs_ma |&gt; \n  ggplot(aes(x = pctBlack, y = PovertyRate)) +\n  geom_point() +\n  labs(x = \"Proportion of Black Population\",\n       y = \"Poverty rate\",\n       title = \"Poverty rate vs. proportion of black population in Opportunity Zone eligible tracts\", \n       subtitle = \"State of Massachusetts\",\n       caption = \"Source: Urban Institute (2018)\") + \n  theme_bw()\n\n\n\n\n\n\n\n\nThere seems to be a slight increase of slope as we move from left to right along the x-axis. But we can make it more explicit by adding a linear trend, and distinguish between the two groups.\n\nozs_ma |&gt; \n  ggplot(aes(x = pctBlack, y = PovertyRate, \n             color = DesignatedOZ)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +   # 'lm' represents linear model\n  labs(x = \"Proportion of Black Population\",\n       y = \"Poverty rate\",\n       title = \"Poverty rate vs. proportion of black population in Opportunity Zone eligible tracts\", \n       subtitle = \"State of Massachusetts\",\n       caption = \"Source: Urban Institute (2018)\") + \n  theme_bw()"
  },
  {
    "objectID": "labs/lab2.html#exercise-1",
    "href": "labs/lab2.html#exercise-1",
    "title": "Exploratory Data Analysis with ",
    "section": "Exercise 1",
    "text": "Exercise 1\nLet‚Äôs first create some summary tables to analyze opportunity zones in Massachusetts.\n\nSuppose you are interested in poverty rates. In Massachusetts, what are the average poverty rates for Opportunity Zones and non-Opportunity Zones?\nWhen you have the result of Question 1 (the summary for Massachusetts), what are the corresponding situations by county in Massachusetts?\nReorganize your previous table, which county has the greatest disparity in poverty rate between designated and non-designated tracts?"
  },
  {
    "objectID": "labs/lab2.html#exercise-2",
    "href": "labs/lab2.html#exercise-2",
    "title": "Exploratory Data Analysis with ",
    "section": "Exercise 2",
    "text": "Exercise 2\nFocus on your Massachusetts data, now choose from our economic and demographic variables to answer the following questions. These include columns from medhhincome to BAorhigher.\n\nSelect one of the variables, create a graphical representation that contrasts its distribution in designated tracts and in undesignated tracts in Massachusetts.\nSelect two variables, create a graphical representation that describes how they relate (or don‚Äôt relate) to each other, including the direction of this relationship.\nWhat can we say about the difference in demographic/economic conditions reflected by these graphs between designated and not designated tracts? Include in your document a few sentences of write-up. You can connect your findings with your summary tables above, and with some broader discussions about Opportunities Zones found here."
  },
  {
    "objectID": "labs/lab2.html#exercise-3",
    "href": "labs/lab2.html#exercise-3",
    "title": "Exploratory Data Analysis with ",
    "section": "Exercise 3",
    "text": "Exercise 3\nIn this part, we will make a Bar Chart. First, let‚Äôs use our familiar group_by + summarise process to calculate the average median household income by county in Massachusetts.\n\nozs_ma |&gt; \n  group_by(county, DesignatedOZ) |&gt;  \n  summarise(\n    Income = mean(medhhincome, na.rm=TRUE)) \n\n# A tibble: 25 √ó 3\n# Groups:   county [13]\n   county            DesignatedOZ   Income\n   &lt;chr&gt;             &lt;chr&gt;           &lt;dbl&gt;\n 1 Barnstable County designated     46717.\n 2 Barnstable County not_designated 61663.\n 3 Berkshire County  designated     35199 \n 4 Berkshire County  not_designated 51122.\n 5 Bristol County    designated     34573.\n 6 Bristol County    not_designated 42035.\n 7 Dukes County      not_designated 46816 \n 8 Essex County      designated     41358.\n 9 Essex County      not_designated 49966.\n10 Franklin County   designated     41711.\n# ‚Ñπ 15 more rows\n\n\nPlease pipe your summarized table to ggplot() for visualization.\nThe geom function you should use here is geom_col.\n\nTake a few minutes to compare the bar chart you created and the one below:\n\n\nThere should be a few differences, which have enhanced the overall quality. How can you modify your code to replicate the bar chart in this image? In a new code chunk, please copy and paste your last bar chart code, and try your best to address the following questions.\n\nThe bars are put side-by-side instead of stacking on top of one another. If you don‚Äôt want a stacked bar chart, you can use the position argument in geom_col.\nThe x-axis labels are titled to 45 degrees. How can I achieve this? Hint.\nThe labels on the y-axis are formatted in thousands with commas. This can be achieved by modifying the function scale_y_continuous(labels = scales::percent) we have seen above. Hint.\nLastly, the counties are not arranged alphabetically, but rather by the income values mapped to the y-axis, starting from large to small. How can I achieve this? Hint.\nPlease add the title, subtitle, x- and y-axis labels, and the data source annotation to your bar chart.\n\nFeel free to consult the¬†R Graph Gallery and Aesthetic specifications for additional resources. If there is anything else you want to experiment, like changing the color scheme or the theme template, go for it."
  },
  {
    "objectID": "lectures/index.html",
    "href": "lectures/index.html",
    "title": "Lecture Overview",
    "section": "",
    "text": "Welcome to the lectures section. Click below to access individual sessions.\n\nLecture 1: Course Overview\nLecture 2: R Programming and Data Manipulation\nLecture 3: Data Transformation and Visualization I\nLecture 4: Data Transformation and Visualization II\nLecture 5: Spatial analysis with R\nLecture 6: Working with Census Data\nLecture 7: Interactive Map and Dashboard\nLecture 8: Web-based storytelling\nLecture 9: Machine Learning: Concepts & Workflow\nLecture 10: Geospatial ML and Hyperparameter Tuning\nLecture 11: Classification Models, Algorithmic Fairness\nLecture 12: Overview of Neural Networks"
  },
  {
    "objectID": "modules/index2.html",
    "href": "modules/index2.html",
    "title": "Module 2 Geospatial Data Science",
    "section": "",
    "text": "We‚Äôll learn how to import, manipulate, and visualize geospatial datasets, from simple maps to more complex spatial analyses.\n\nSpatial analysis\nMapping census data"
  },
  {
    "objectID": "modules/index4.html",
    "href": "modules/index4.html",
    "title": "Module 4 Predictive Data Science",
    "section": "",
    "text": "Introduces modern machine learning methods. We‚Äôll work on the skills to move from describing what has happened to predicting what is likely to happen next.\n\nMachine Learning: Concepts & Workflow\nML Models and Hyperparameter Tuning\nClassification, Fairness-aware ML\nOverview of Neural Networks"
  }
]